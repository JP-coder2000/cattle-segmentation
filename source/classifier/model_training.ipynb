{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from CowClassifier import CowClassifier\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "# Parameters\n",
    "images_per_class = 250  # Desired number of images per class\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class CowDataset(Dataset):\n",
    "    def __init__(self, root_dir, images_per_class=500, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.images_per_class = images_per_class\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        # Define class labels\n",
    "        self.class_labels = {'vaca_acostada': 0, 'vaca_de_pie': 1}\n",
    "        self.class_counts = {label: 0 for label in self.class_labels.values()}\n",
    "        \n",
    "        # File extensions to consider\n",
    "        valid_image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]\n",
    "        \n",
    "        # Load images from each numbered folder (1-8)\n",
    "        for folder_num in range(1, 9):\n",
    "            folder_path = os.path.join(root_dir, str(folder_num))\n",
    "            for class_name, label in self.class_labels.items():\n",
    "                class_folder = os.path.join(folder_path, class_name)\n",
    "                \n",
    "                if not os.path.exists(class_folder):\n",
    "                    continue\n",
    "                \n",
    "                for filename in os.listdir(class_folder):\n",
    "                    if self.class_counts[label] >= self.images_per_class:\n",
    "                        break\n",
    "                    \n",
    "                    if any(filename.lower().endswith(ext) for ext in valid_image_extensions):\n",
    "                        img_path = os.path.join(class_folder, filename)\n",
    "                        try:\n",
    "                            img = Image.open(img_path)\n",
    "                            if self.transform:\n",
    "                                img = self.transform(img)\n",
    "                            self.data.append((img, label))\n",
    "                            self.class_counts[label] += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        return image, label\n",
    "\n",
    "# Instantiate datasets and dataloaders\n",
    "train_dataset = CowDataset(root_dir=\"images\", images_per_class=images_per_class, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print dataset summary\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "for class_name, label in train_dataset.class_labels.items():\n",
    "    print(f\"Number of images for class '{class_name}': {train_dataset.class_counts[label]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional data augmentation transformations\n",
    "# Adjusted augmentations\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Custom Dataset with Augmentation (corrected) \n",
    "class AugmentedCowDataset(Dataset):\n",
    "    def __init__(self, original_dataset, augment_transform):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Original dataset length times two (for each augmented copy)\n",
    "        return len(self.original_dataset) * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx // 2\n",
    "        image, label = self.original_dataset[original_idx]\n",
    "        \n",
    "        \n",
    "        # Convert tensor back to PIL for augmentation\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        # Apply augmentation on every second image\n",
    "        if idx % 2 == 1:\n",
    "            image = self.augment_transform(image)\n",
    "        else:\n",
    "            # Convert original image to tensor (if not already)\n",
    "            image = transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Instantiate augmented dataset\n",
    "augmented_dataset = AugmentedCowDataset(train_dataset, augment_transform)\n",
    "\n",
    "# Create a DataLoader for the augmented dataset\n",
    "augmented_loader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Original dataset size: {len(train_dataset)}\")\n",
    "print(f\"Augmented dataset size: {len(augmented_dataset)}\")\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "model = CowClassifier().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# Manually define weights for each class \n",
    "manual_weights = torch.tensor([3.0, 2.0], dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function with manual weights\n",
    "criterion = nn.CrossEntropyLoss(weight=manual_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_labels, all_preds\n",
    "\n",
    "\n",
    "epochs=15\n",
    "# Train on augmented data\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the augmented dataset\n",
    "train_accuracy, train_labels, train_preds = evaluate(model, train_loader)\n",
    "print(f\"Training Accuracy on Augmented Data: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nClassification Report on Augmented Data:\")\n",
    "print(classification_report(train_labels, train_preds, target_names=train_dataset.class_labels.keys()))\n",
    "\n",
    "cm = confusion_matrix(train_labels, train_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.class_labels.keys())\n",
    "disp.plot(cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix (Augmented Data)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, '../models/classifier/cow_class_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/classifier/cow_class_model_state.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
